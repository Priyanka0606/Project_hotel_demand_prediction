{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1488b44",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9662e6",
   "metadata": {},
   "source": [
    "Leverage Guest Data and Booking behaviour patterns to devise a strategy for Hotel Revenue management, using Data science and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb53fd6",
   "metadata": {},
   "source": [
    "### Importing the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea4573a",
   "metadata": {},
   "source": [
    "### Importing the data for ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df71a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('/Users/priyankac/Downloads/hotel_bookings (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d066b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abc86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first five records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dcd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking different data types in the given data set\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d6fa5",
   "metadata": {},
   "source": [
    "### Setting display options to ensure feature name visiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ceafd",
   "metadata": {},
   "source": [
    "### Warning Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d921400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b2274",
   "metadata": {},
   "source": [
    "### Drop ID Feature from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e4b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No ID feature is mentioned in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d8106",
   "metadata": {},
   "source": [
    "### Defining Target and Independent Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[['is_canceled']]\n",
    "X = df.drop(['is_canceled'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb364db4",
   "metadata": {},
   "source": [
    "### Get the Cancellation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7940b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the event rate (cancellation rate)\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76340ac",
   "metadata": {},
   "source": [
    "### Split features into Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899564e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = X.select_dtypes(include = 'number')\n",
    "char1 = X.select_dtypes(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d573ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "char1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the levels of feature in the numerical column\n",
    "# If the level <= 20 they will be considered as categorical feature\n",
    "\n",
    "def unique_levels(x):\n",
    "    x = x.value_counts().count()\n",
    "    return (x)\n",
    "\n",
    "df_value_counts = pd.DataFrame(num1.apply(lambda x : unique_levels(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3418730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_counts.columns = ['feature_levels']\n",
    "df_value_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814934e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing all the features that has levels less than 20 and storing in separate df\n",
    "slice1 = df_value_counts.loc[df_value_counts['feature_levels'] <= 20]\n",
    "cat_list = slice1.index\n",
    "cat = num1.loc[: , cat_list]\n",
    "cat.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189dae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the feature levels greater than 20 in num DataFrame\n",
    "slice2 = df_value_counts.loc[df_value_counts['feature_levels'] > 20]\n",
    "num_list = slice2.index\n",
    "num1 = num1.loc[: , num_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e81f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the cat dataframe with the char dataframe\n",
    "char1 = pd.concat([char1, cat], axis = 1, join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1759f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "char1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d526d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "char1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "char1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb57b3d",
   "metadata": {},
   "source": [
    "### Outlier Analysis of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7787338",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.describe(percentiles = [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.85, 0.90, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0c2b9",
   "metadata": {},
   "source": [
    "### Capping and Flooring of Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0036762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_cap(x):\n",
    "    x = x.clip(lower = x.quantile(0.01))\n",
    "    x = x.clip(upper = x.quantile(0.99))\n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = num1.apply(lambda x : outlier_cap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.describe(percentiles = [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.85, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b64015",
   "metadata": {},
   "source": [
    "### Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61dd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "char1.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5bd37",
   "metadata": {},
   "source": [
    "### Dropping variables that have > 25% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c50873",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1 = num1.loc[:,num1.isnull().mean() <= .25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c409b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num1.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98c6c8",
   "metadata": {},
   "source": [
    "### Imputation of Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f76e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Imputation For numerical features\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "num_1 = pd.DataFrame(imputer.fit_transform(num1), index = num1.index, columns = num1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_1.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation for Categorical features\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "char_1 = pd.DataFrame(imputer.fit_transform(char1), index = char1.index, columns = char1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ce4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_1.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f2c3fe",
   "metadata": {},
   "source": [
    "## Feature Selection - Numerical Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c8846",
   "metadata": {},
   "source": [
    "### Part 1 : Remove Features with 0 Variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec18745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "varselector = VarianceThreshold(threshold = 0)\n",
    "varselector.fit_transform(num_1)\n",
    "\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = varselector.get_support(indices = True)\n",
    "num_2 = num_1.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd60c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_2.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34857c",
   "metadata": {},
   "source": [
    "### Part 2 : Bi Variate Analysis (Feature Discretization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beae009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discrete = KBinsDiscretizer(n_bins = 10, encode = 'ordinal', strategy = 'quantile')\n",
    "num_binned = pd.DataFrame(discrete.fit_transform(num_2), index = num_2.index, \n",
    "                          columns = num_2.columns).add_suffix('_Rank')\n",
    "num_binned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c59f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the features show a slope at all\n",
    "# If they do, then do you see some deciles below the population average and some higher than population?\n",
    "# If that is the case then the slope will be strong\n",
    "\n",
    "# Conclusion: A strong slope is indicative of the features' ability to discriminate the event from non event\n",
    "#             making it a good predictor\n",
    "\n",
    "X_bin_combined = pd.concat([Y, num_binned], axis = 1, join = 'inner')\n",
    "\n",
    "from numpy import mean\n",
    "for col in (num_binned.columns):\n",
    "    plt.figure()\n",
    "    sns.lineplot(x = col, y = X_bin_combined['is_canceled'].mean(), data = X_bin_combined, color = 'red')\n",
    "    sns.barplot(x = col, y = 'is_canceled', data = X_bin_combined, estimator = mean)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd124e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the descriptive statistics for the following features:\n",
    "# previous_bookings_not_canceled\n",
    "# days_in_waiting_list\n",
    "# booking_changes\n",
    "\n",
    "num_2['day_wait_ind'] = np.where(num_2['days_in_waiting_list'] > 0, 1, 0)\n",
    "num_2['previous_bookings_not_canceled_ind'] = np.where(num_2['previous_bookings_not_canceled'] > 0, 1, 0)\n",
    "num_2['booking_changes_ind'] = np.where(num_2['booking_changes'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c46f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_varlist = ['arrival_date_week_number', 'arrival_date_day_of_month', 'previous_bookings_not_canceled',\n",
    "              'booking_changes', 'days_in_waiting_list']\n",
    "num_2 = num_2.drop(num_varlist, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378e186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e04647",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdaad68",
   "metadata": {},
   "source": [
    "### Part 3 : Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "selector = SelectKBest(chi2, k = 4)\n",
    "selector.fit_transform(num_2, Y)\n",
    "\n",
    "# Get columns to keep and create new dataframe with only those\n",
    "cols = selector.get_support(indices = True)\n",
    "select_features_df_num = num_2.iloc[: , cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_df_num.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7333dd7f",
   "metadata": {},
   "source": [
    "## Feature Selection - Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b561c",
   "metadata": {},
   "source": [
    "### Part 1 : Bi Variate Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5135b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_char_merged = pd.concat([char1, Y], axis = 1, join = 'inner')\n",
    "\n",
    "from numpy import mean\n",
    "for col in (char1.columns):\n",
    "    plt.figure()\n",
    "    sns.barplot(x = col, y = 'is_canceled', data = X_char_merged, estimator = mean)\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555bde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "charlist = ['arrival_date_month', 'country', 'assigned_room_type', 'reservation_status',\n",
    "           'reservation_status_date', 'arrival_month_year']\n",
    "char_1 = char_1.drop(charlist, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ba3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy features with the n-1 levels(One Hot Encoding)\n",
    "X_char_dum = pd.get_dummies(char_1, drop_first = True)\n",
    "X_char_dum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed1a249",
   "metadata": {},
   "source": [
    "### Part 2 : Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34668480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select K Best for Categorical Features\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "selector = SelectKBest(chi2, k = 90)\n",
    "selector.fit_transform(X_char_dum, Y)\n",
    "\n",
    "# Get columns to keep and create a dataframe with those only\n",
    "cols = selector.get_support(indices = True)\n",
    "select_features_df_char = X_char_dum.iloc[: , cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e696a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_df_char.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2a0fb",
   "metadata": {},
   "source": [
    "## Creating the Master Feature Set for Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347eeab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([select_features_df_num, select_features_df_char], axis = 1, join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f901215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9217903",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, Y, test_size = 0.3, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of Training Data ',X_train.shape)\n",
    "print('Shape of Testing Data', X_test.shape)\n",
    "print('Response rate in Training Data', y_train.mean())\n",
    "print('Response rate in Testing Data', y_test.mean())\n",
    "# mean of training and testing data are almost same indicating a good representation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cdaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Linearity in feature relationships are observed which makes tree based methods a good choice\n",
    "# There are few options to consider among Tree methods:\n",
    "# White Box(Completely explainable set of rules )- Decision Tree\n",
    "# Ensemble Method - Random forest(with Bagging)\n",
    "# Ensemble method - GBM/XGBoost(Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Decision Tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(criterion = 'gini', random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc013cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_dist = {'max_depth' : [3, 5, 6, 7], 'min_samples_split' : [140, 280, 420, 560, 700]}\n",
    "tree_grid = GridSearchCV(dtree, cv = 10, param_grid = param_dist, n_jobs = -1)\n",
    "tree_grid.fit(X_train, y_train)\n",
    "print('Best Parameters using Grid Search: \\n', tree_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a790af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(criterion = 'gini', random_state = 20, max_depth = 7, min_samples_split = 140)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb83598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(criterion = 'gini', random_state = 20, max_depth = 7, min_samples_split = 140)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Gradient Boosting Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier(criterion = 'mse', random_state = 20, max_depth = 7, min_samples_split = 140)\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eac4c8",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c468f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tree = dtree.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_gbm = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bff4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8142cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Decision Tree\n",
    "print('Accuracy : ', metrics.accuracy_score(y_test, y_pred_tree))\n",
    "print('Precision : ', metrics.precision_score(y_test, y_pred_tree))\n",
    "print('Recall : ', metrics.recall_score(y_test, y_pred_tree))\n",
    "print('f1_score : ', metrics.f1_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "metrics.plot_confusion_matrix(dtree, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df639869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Random Forest\n",
    "print('Accuracy : ', metrics.accuracy_score(y_test, y_pred_rf))\n",
    "print('Precision : ', metrics.precision_score(y_test, y_pred_rf))\n",
    "print('Recall : ', metrics.recall_score(y_test, y_pred_rf))\n",
    "print('f1_score : ', metrics.f1_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea719e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "metrics.plot_confusion_matrix(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for Gradient Boosting\n",
    "print('Accuracy : ', metrics.accuracy_score(y_test, y_pred_gbm))\n",
    "print('Precision : ', metrics.precision_score(y_test, y_pred_gbm))\n",
    "print('Recall : ', metrics.recall_score(y_test, y_pred_gbm))\n",
    "print('f1_score : ', metrics.f1_score(y_test, y_pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21149f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "metrics.plot_confusion_matrix(gbm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b6abb",
   "metadata": {},
   "source": [
    "### Lorenze Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce6355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Gradient boost is giving the best results, we use Lorenz curve based on output from Gradient Boosting Model\n",
    "\n",
    "y_pred_prob = gbm.predict_proba(X_all)[:, 1]\n",
    "\n",
    "#as output of y_pred_prob is an array convert to dataframe, add as new column in our dataframe df\n",
    "df['pred_prob_gbm'] = pd.DataFrame(y_pred_prob)\n",
    "\n",
    "#creating decile out of the y_pred_prob(to a group of people to find churners and then apply strategy for their \n",
    "#retention) (codes+1 ensures that we have the same number of people in each group) \n",
    "df['P_Rank_gbm'] = pd.qcut(df['pred_prob_gbm'].rank(method='first').values, 10, duplicates='drop').codes+1 \n",
    "\n",
    "# creating another dataframe using just the columns is_canceled and y_pred_P\n",
    "rank_df_actuals = df.groupby('P_Rank_gbm')['is_canceled'].agg(['count', 'mean'])\n",
    "rank_df_actuals = pd.DataFrame(rank_df_actuals)\n",
    "rank_df_actuals.rename(columns = {'mean' : 'Actual_event_rate'}, inplace = True)\n",
    "\n",
    "rank_df_predicted = df.groupby('P_Rank_gbm')['y_pred_P'].agg(['mean'])\n",
    "rank_df_predicted = pd.DataFrame(rank_df_predicted)\n",
    "rank_df_predicted.rename(columns = {'mean': 'Predicted_event_rate'}, inplace = True)\n",
    "\n",
    "rank_df = pd.concat([rank_df_actuals, rank_df_predicted], axis = 1, join = 'inner')\n",
    "\n",
    "#sorting the dataframe in descending order\n",
    "sorted_rank_df = rank_df.sort_values(by = 'P_Rank_gbm' , ascending = False)\n",
    "sorted_rank_df['N_events'] = rank_df['count'] * rank_df['Actual_event_rate']# number of people who churned\n",
    "sorted_rank_df['cum_events'] = sorted_rank_df['N_events'].cumsum()#cumulating the number of people churned\n",
    "sorted_rank_df['event_cap'] = sorted_rank_df['N_events']/max(sorted_rank_df['N_events'].cumsum())#event capture rate\n",
    "sorted_rank_df['cum_event_cap'] = sorted_rank_df['event_cap'].cumsum()\n",
    "\n",
    "# calculating non events\n",
    "sorted_rank_df['N_non_events'] = sorted_rank_df['count'] - sorted_rank_df['N_events']#number of non events\n",
    "sorted_rank_df['cum_non_events'] = sorted_rank_df['N_non_events'].cumsum()\n",
    "sorted_rank_df['non_event_cap'] = sorted_rank_df['N_non_events']/max(sorted_rank_df['N_non_events'].cumsum())\n",
    "sorted_rank_df['cum_non_event_cap'] = sorted_rank_df['non_event_cap'].cumsum()\n",
    "\n",
    "\n",
    "# Using KS-The KS test report the maximum difference between the two cumulative distributions, \n",
    "# and we see where the gap maximizes\n",
    "sorted_rank_df['KS'] = round((sorted_rank_df['cum_event_cap'] - sorted_rank_df['cum_non_event_cap']), 4) \n",
    "\n",
    "sorted_rank_df['random_cap'] = sorted_rank_df['count']/max(sorted_rank_df['count'].cumsum())\n",
    "sorted_rank_df['cum_random_cap'] = sorted_rank_df['random_cap'].cumsum()\n",
    "\n",
    "sorted_reindexed = sorted_rank_df.reset_index()\n",
    "sorted_reindexed['Decile'] = sorted_reindexed.index+1\n",
    "sorted_reindexed['Lift_over_Avg']=sorted_reindexed['Actual_event_rate']/(max(sorted_reindexed['N_events'].cumsum())/max(sorted_reindexed['count'].cumsum()))\n",
    "\n",
    "                                                            \n",
    "sorted_reindexed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e1380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting graphs\n",
    "fig, axes = plt.subplots(1,2, sharex = True, figsize = (15,5))\n",
    "fig.suptitle('Effectiveness of Deciles based on Model Probabilities')\n",
    "axes[0].set_title('Rank Ordering of Actual Event Rate')\n",
    "#axes[1].set_title('Lift over Mean Event Rate')\n",
    "axes[1].set_title('Gains Chart')\n",
    "sns.lineplot(ax=axes[0], x='Decile', y='Actual_event_rate', data=sorted_reindexed, color='red')\n",
    "#sns.barplot(ax=axes[1], x='Decile', y='Lift_over_avg', data=sorted_reindexed, color='green')\n",
    "sns.lineplot(ax=axes[1], x='Decile', y='cum_event_cap', data=sorted_reindexed, color='blue')\n",
    "sns.lineplot(ax=axes[1], x='Decile', y='cum_non_event_cap', data=sorted_reindexed, color='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From machine learning to strategy\n",
    "# Introduction APT framework\n",
    "# A-Audience\n",
    "# P-Prioritization\n",
    "# T-Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7817ad",
   "metadata": {},
   "source": [
    "### Audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Predicted_cancel_Rank'] = np.where(df['P_Rank_gbm'] < 8, 'Bottom 7', 'Top 3')\n",
    "df.Predicted_cancel_Rank.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b58f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top3 = df.loc[df['Predicted_cancel_Rank'] == 'Top 3', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dd620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b02bb0",
   "metadata": {},
   "source": [
    "### Prioritization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lead_time_RANK'] = pd.qcut(df['lead_time'].rank(method = 'first').values, 10, duplicates = 'drop').codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('lead_time_RANK')['lead_time'].agg(['min','mean', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lead_time.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fa43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering the mean greater than equal to 7 is considered as high lead time\n",
    "df['lead_time_segment'] = np.where(df['lead_time_RANK'] >= 7, 'High Lead Time', 'Low Lead Time')\n",
    "df.lead_time_segment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be762a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adr_RANK'] = pd.qcut(df['adr'].rank(method = 'first').values, 10, duplicates = 'drop').codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('adr_RANK')['adr'].agg(['min', 'mean', 'max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.adr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c067cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adr_segment'] = np.where(df['adr_RANK'] >= 7, 'High ADR', 'Low ADR')\n",
    "df.adr_segment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63fade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df['adr_segment'], columns=df['lead_time_segment'], values=df['adr'],aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df['adr_segment'], columns=df['lead_time_segment'], values=df['is_canceled'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36eff6a",
   "metadata": {},
   "source": [
    "### Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d21f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_list =['stays_in_weekend_nights','total_of_special_requests', 'reserved_room_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fe24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top3_services = df_top3[service_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f212f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (df_top3_services.columns):\n",
    "    plt.figure()\n",
    "    sns.countplot(x = col, data = df_top3_services)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e534b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12246942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848e255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
